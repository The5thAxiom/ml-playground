{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "with open('sherlock.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "text = text.lower()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation\n",
    "- The maximum likelihood of a sequence $$w_{i-n+1},\\dots ,w_{i-2},w_{i-1},w_i$$ is the likelihood of $w_i$ coming after the sequence $$w_{i-n+1},\\dots ,w_{i-2},w_{i-1}$$\n",
    "- Thus,\n",
    "$$\n",
    "P(w_i|w_{i-n+1},\\dots ,w_{i-2},w_{i-1}) = \\frac{\n",
    "    C(w_{i-n+1},\\dots ,w_{i-2},w_{i-1},w_i)\n",
    "    }{\n",
    "        \\sum_w C(w_{i-n+1},\\dots ,w_{i-2},w_{i-1},w)\n",
    "    }\n",
    "$$\n",
    "- Now, the number of n-grams starting with $w_{i-n},\\dots ,w_{i-2},w_{i-1}$ is the same as the number of times the sequence appears, thus $$  \\sum_w C(w_{i-n},\\dots ,w_{i-2},w_{i-1},w) = C(w_{i-n},\\dots ,w_{i-2},w_{i-1}) $$\n",
    "- Thus, the MLE becomes\n",
    "$$\n",
    "P(w_i|w_{i-n+1},\\dots ,w_{i-2},w_{i-1}) = \\frac{\n",
    "    C(w_{i-n+1},\\dots ,w_{i-2},w_{i-1},w_i)\n",
    "    }{\n",
    "        C(w_{i-n+1},\\dots ,w_{i-2},w_{i-1})\n",
    "    }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mle(word: str, prev_words: tuple[str], n_grams: list[tuple[str, ...]], sentences: list[list[str]], n: int) -> float:\n",
    "    sequence = tuple(prev_words+(word,))\n",
    "    n1_grams = make_ngrams(sentences, n-1)\n",
    "    count_sequence = n_grams.count(prev_words + (word,))\n",
    "    count_prev = n1_grams.count(prev_words)\n",
    "    return count_sequence/count_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mle('I', ('<s>',), n_grams, sentences, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "0.6666666666666666\n",
      "0.5\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(mle('Sam', ('<s>',), n_grams, sentences, n))\n",
    "print(mle('am', ('I',), n_grams, sentences, n))\n",
    "print(mle('Sam', ('am',), n_grams, sentences, n))\n",
    "print(mle('do', ('I',), n_grams, sentences, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramModel:\n",
    "    def __init__(self, text: str, n: int, keep_punctuation: bool=False):\n",
    "        self.text = text\n",
    "        self.n = n\n",
    "        sentences, words = self._tokenize(keep_punctuation)\n",
    "        self.n_grams = self._make_n_grams(sentences, n)\n",
    "        self.n1_grams = self._make_n_grams(sentences, n-1)\n",
    "\n",
    "    def _tokenize(self, keep_punctuation: bool):\n",
    "        sentences = [\n",
    "            word_tokenize(sentence)\n",
    "                for sentence in sent_tokenize(self.text)\n",
    "        ]\n",
    "        sentences = [(\n",
    "            ['<s>']*(n-1) + sentence + ['</s>']*(n-1)\n",
    "        ) for sentence in sentences]\n",
    "        \n",
    "        punctutation=['.', ',', '!', '?']\n",
    "        words = [\n",
    "            word\n",
    "                for sentence in sentences\n",
    "                    for word in sentence\n",
    "        ]\n",
    "\n",
    "        if not keep_punctuation:\n",
    "            sentences = [\n",
    "                [word for word in sentence\n",
    "                    if word not in punctutation]\n",
    "                for sentence in sentences\n",
    "            ]\n",
    "            words = [\n",
    "                word for word in words\n",
    "                    if word not in punctutation\n",
    "            ]\n",
    "        return sentences, words\n",
    "\n",
    "    def _make_n_grams(self, sentences: list[list[str]], n: int) -> list[tuple[str, ...]]:\n",
    "        n_grams = [\n",
    "            ng for sentence in sentences\n",
    "                for ng in ngrams(sentence, n)\n",
    "        ]\n",
    "        return n_grams\n",
    "\n",
    "    def getMLE(self, word: str, prev_words: tuple[str]) -> float:\n",
    "        sequence = tuple(prev_words+(word,))\n",
    "        count_sequence = self.n_grams.count(sequence)\n",
    "        count_prev = self.n1_grams.count(prev_words)\n",
    "        mle = count_sequence/count_prev\n",
    "        print({\n",
    "            'cs': count_sequence,\n",
    "            'cp': count_prev,\n",
    "            'mle': mle\n",
    "        })\n",
    "        return mle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I am Sam. Sam I am. I do not like green eggs and ham'\n",
    "n = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cs': 1, 'cp': 3, 'mle': 0.3333333333333333}\n",
      "{'cs': 2, 'cp': 3, 'mle': 0.6666666666666666}\n",
      "{'cs': 1, 'cp': 2, 'mle': 0.5}\n",
      "{'cs': 1, 'cp': 3, 'mle': 0.3333333333333333}\n",
      "{'cs': 2, 'cp': 3, 'mle': 0.6666666666666666}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngm = NGramModel(text, 2)\n",
    "ngm.getMLE('Sam', ('<s>',))\n",
    "ngm.getMLE('I', ('<s>',))\n",
    "ngm.getMLE('</s>', ('Sam',))\n",
    "ngm.getMLE('do', ('I',))\n",
    "ngm.getMLE('am', ('I',))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
