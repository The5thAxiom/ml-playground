{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log, exp, prod\n",
    "from pprint import pprint\n",
    "\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation\n",
    "- The maximum likelihood of a sequence $$w_{i-n+1},\\dots ,w_{i-2},w_{i-1},w_i$$ is the likelihood of $w_i$ coming after the sequence $$w_{i-n+1},\\dots ,w_{i-2},w_{i-1}$$\n",
    "- Thus,\n",
    "$$\n",
    "P(w_i|w_{i-n+1},\\dots ,w_{i-2},w_{i-1}) = \\frac{\n",
    "    C(w_{i-n+1},\\dots ,w_{i-2},w_{i-1},w_i)\n",
    "    }{\n",
    "        \\sum_w C(w_{i-n+1},\\dots ,w_{i-2},w_{i-1},w)\n",
    "    }\n",
    "$$\n",
    "- Now, the number of n-grams starting with $w_{i-n},\\dots ,w_{i-2},w_{i-1}$ is the same as the number of times the sequence appears, thus $$  \\sum_w C(w_{i-n},\\dots ,w_{i-2},w_{i-1},w) = C(w_{i-n},\\dots ,w_{i-2},w_{i-1}) $$\n",
    "- Thus, the MLE becomes\n",
    "$$\n",
    "P(w_i|w_{i-n+1},\\dots ,w_{i-2},w_{i-1}) = \\frac{\n",
    "    C(w_{i-n+1},\\dots ,w_{i-2},w_{i-1},w_i)\n",
    "    }{\n",
    "        C(w_{i-n+1},\\dots ,w_{i-2},w_{i-1})\n",
    "    }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramModel:\n",
    "    def __init__(self, text: str, n: int, keep_punctuation: bool=False, verbose: bool=False):\n",
    "        self.text = text\n",
    "        self.n = n\n",
    "        self.verbose = verbose\n",
    "        self.keep_punctuation = keep_punctuation\n",
    "        sentences, words = self._tokenize(text)\n",
    "        self.n_grams = self._make_n_grams(sentences, n)\n",
    "        self.n1_grams = self._make_n_grams(sentences, n-1)\n",
    "        # if self.verbose:\n",
    "            # pprint(self.n_grams)\n",
    "\n",
    "    def _tokenize(self, text: str):\n",
    "        sentences = [\n",
    "            word_tokenize(sentence)\n",
    "                for sentence in sent_tokenize(text)\n",
    "        ]\n",
    "        sentences = [(\n",
    "            ['<s>']*(self.n-1) + sentence + ['</s>']*(self.n-1)\n",
    "        ) for sentence in sentences]\n",
    "        \n",
    "        punctutation=['.', ',', '!', '?']\n",
    "        words = [\n",
    "            word\n",
    "                for sentence in sentences\n",
    "                    for word in sentence\n",
    "        ]\n",
    "\n",
    "        if not self.keep_punctuation:\n",
    "            sentences = [\n",
    "                [word for word in sentence\n",
    "                    if word not in punctutation]\n",
    "                for sentence in sentences\n",
    "            ]\n",
    "            words = [\n",
    "                word for word in words\n",
    "                    if word not in punctutation\n",
    "            ]\n",
    "        return sentences, words\n",
    "\n",
    "    def _make_n_grams(self, sentences: list[list[str]], n: int) -> list[tuple[str, ...]]:\n",
    "        n_grams = [\n",
    "            ng for sentence in sentences\n",
    "                for ng in ngrams(sentence, n)\n",
    "        ]\n",
    "        return n_grams\n",
    "\n",
    "    def getMLE(self, word: str, prev_words: tuple[str]) -> float:\n",
    "        if len(prev_words) >= self.n:\n",
    "            raise ValueError('prev_words should have length n-1')\n",
    "        if len(prev_words) < self.n-1:\n",
    "            prev_words = ('<s>',)*(self.n-1-len(prev_words)) + prev_words\n",
    "        sequence = tuple(prev_words+(word,))\n",
    "        count_sequence = self.n_grams.count(sequence)\n",
    "        count_prev = self.n1_grams.count(prev_words)\n",
    "        if count_prev == 0:\n",
    "            mle = 0\n",
    "        else:\n",
    "            mle = count_sequence/count_prev\n",
    "        if self.verbose:\n",
    "            pprint({\n",
    "                'seq': sequence,\n",
    "                'cs': count_sequence,\n",
    "                'prev': prev_words,\n",
    "                'cp': count_prev,\n",
    "                'mle': mle\n",
    "            })\n",
    "        return mle\n",
    "\n",
    "    def getSentenceProb(self, sentence: str) -> float:\n",
    "        tokenized_sentence, _ = self._tokenize(sentence)\n",
    "        s = tokenized_sentence[0]\n",
    "        prob = 1\n",
    "        prob_pairs = [(\n",
    "            sent,\n",
    "            tuple(s[i-self.n+1:i])\n",
    "        ) for i, sent in enumerate(s)][self.n-1:]\n",
    "        prob = prod([self.getMLE(*pair) for pair in prob_pairs])\n",
    "        # prob = exp(sum([log(self.getMLE(*pair)) for pair in prob_pairs]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I am Sam. Sam I am. I do not like green eggs and ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngm = NGramModel(text, 2)\n",
    "ngm.getSentenceProb('I am Sam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cp': 3,\n",
      " 'cs': 1,\n",
      " 'mle': 0.3333333333333333,\n",
      " 'prev': ('<s>',),\n",
      " 'seq': ('<s>', 'Sam')}\n",
      "{'cp': 3,\n",
      " 'cs': 2,\n",
      " 'mle': 0.6666666666666666,\n",
      " 'prev': ('<s>',),\n",
      " 'seq': ('<s>', 'I')}\n",
      "{'cp': 2, 'cs': 1, 'mle': 0.5, 'prev': ('Sam',), 'seq': ('Sam', '</s>')}\n",
      "{'cp': 3,\n",
      " 'cs': 1,\n",
      " 'mle': 0.3333333333333333,\n",
      " 'prev': ('I',),\n",
      " 'seq': ('I', 'do')}\n",
      "{'cp': 3,\n",
      " 'cs': 2,\n",
      " 'mle': 0.6666666666666666,\n",
      " 'prev': ('I',),\n",
      " 'seq': ('I', 'am')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngm = NGramModel(text, 2, verbose=True)\n",
    "ngm.getMLE('Sam', ('<s>',))\n",
    "ngm.getMLE('I', ('<s>',))\n",
    "ngm.getMLE('</s>', ('Sam',))\n",
    "ngm.getMLE('do', ('I',))\n",
    "ngm.getMLE('am', ('I',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngm = NGramModel(text, 2)\n",
    "ngm.getMLE('Sam', ('<s>',))\n",
    "ngm.getMLE('I', ('<s>',))\n",
    "ngm.getMLE('</s>', ('Sam',))\n",
    "ngm.getMLE('do', ('I',))\n",
    "ngm.getMLE('am', ('I',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = NGramModel('who are you. who am i. i am you', 2)\n",
    "mod.getMLE('are', ('who',))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams for the Sherlock Holmes Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "sherlock_text = ''\n",
    "with open('sherlock.txt', 'r') as file:\n",
    "    sherlock_text = file.read()\n",
    "sherlock_text = sherlock_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "shngm = NGramModel(sherlock_text, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9448441247002398"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shngm.getMLE('holmes', ('sherlock',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006805867582925862"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shngm.getMLE('when', ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.570162194609999e-06"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shngm.getSentenceProb('what happened')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4828968718906952e-06\n",
      "0.003089598352214212\n"
     ]
    }
   ],
   "source": [
    "print(shngm.getSentenceProb('from holmes'))\n",
    "print(shngm.getMLE('holmes', ('from',)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
